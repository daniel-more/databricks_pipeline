{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b10f7f4-22cf-471e-8c94-83c8ff269595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Building Out Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0ac167-9a95-4aba-8111-df04056ad2f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "VOLUME_ROOT_PATH = \"/Volumes/cscie103_catalog/final_project\"\n",
    "VOLUME_DATA_DIR = f\"{VOLUME_ROOT_PATH}/data\"\n",
    "\n",
    "CATALOG_NAME = \"cscie103_catalog\"\n",
    "SCHEMA_NAME = \"final_project\"\n",
    "spark.sql(f\"USE {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "\n",
    "class DataframeNames:\n",
    "    HOLIDAYS = \"holidays\"\n",
    "    OIL = \"oil\"\n",
    "    STORES = \"stores\"\n",
    "    TEST = \"test\"\n",
    "    TRAIN = \"train\"\n",
    "    TRANSACTIONS = \"transactions\"\n",
    "    TRAINING = \"training\"\n",
    "\n",
    "    ALL = [ HOLIDAYS, OIL, STORES, TEST, TRAIN, TRANSACTIONS, TRAINING ]\n",
    "\n",
    "class DataTier:\n",
    "    BRONZE = \"bronze\"\n",
    "    SILVER = \"silver\"\n",
    "    GOLD = \"gold\"\n",
    "\n",
    "    def getBronzeName(tablename):\n",
    "        return DataTier.BRONZE + \"_\" + tablename\n",
    "\n",
    "    def getSilverName(tablename):\n",
    "        return DataTier.SILVER + \"_\" + tablename\n",
    "    \n",
    "    def getGoldName(tablename):\n",
    "        return DataTier.GOLD + \"_\" + tablename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e36281a-40bc-4767-a7fe-e45bee6263f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Use the right catalog & schema\n",
    "spark.sql(\"USE cscie103_catalog.final_project\")\n",
    "\n",
    "# Load Silver tables\n",
    "silver_train  = spark.table(DataTier.getSilverName(DataframeNames.TRAIN))\n",
    "silver_stores = spark.table(DataTier.getSilverName(DataframeNames.STORES))\n",
    "silver_oil    = spark.table(DataTier.getSilverName(DataframeNames.OIL))\n",
    "silver_hol    = spark.table(DataTier.getSilverName(DataframeNames.HOLIDAYS))\n",
    "silver_tx     = spark.table(DataTier.getSilverName(DataframeNames.TRANSACTIONS))\n",
    "\n",
    "# Enriched base fact: one row per date-store-family\n",
    "base_fact = (\n",
    "    silver_train.alias(\"t\")\n",
    "    .join(silver_stores.alias(\"s\"), \"store_nbr\", \"left\")\n",
    "    .join(silver_tx.alias(\"x\"), [\"date\", \"store_nbr\"], \"left\")\n",
    "    .join(silver_oil.alias(\"o\"), \"date\", \"left\")\n",
    "    .join(silver_hol.alias(\"h\"), \"date\", \"left\")\n",
    "    .select(\n",
    "        F.col(\"t.date\").alias(\"date\"),\n",
    "        F.col(\"t.store_nbr\").alias(\"store_nbr\"),\n",
    "        F.col(\"t.family\").alias(\"family\"),\n",
    "        F.col(\"t.sales\").alias(\"sales\"),\n",
    "        F.col(\"t.onpromotion\").alias(\"onpromotion\"),\n",
    "        F.col(\"x.transactions\").alias(\"transactions\"),\n",
    "        F.col(\"o.dcoilwtico\").alias(\"dcoilwtico\"),\n",
    "        F.col(\"s.city\").alias(\"city\"),\n",
    "        F.col(\"s.state\").alias(\"state\"),\n",
    "        F.col(\"s.type\").alias(\"store_type\"),\n",
    "        F.col(\"s.cluster\").alias(\"cluster\"),\n",
    "        F.col(\"h.is_holiday\").alias(\"is_holiday\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Databricks notebook: 03_gold_daily_fact\n",
    "# Default language: Python\n",
    "\n",
    "# =========================================\n",
    "# 1. Setup\n",
    "# =========================================\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "catalog = \"cscie103_catalog\"\n",
    "schema  = \"final_project\"\n",
    "\n",
    "spark.sql(f\"USE {catalog}.{schema}\")\n",
    "\n",
    "# =========================================\n",
    "# 2. Load Silver tables\n",
    "# =========================================\n",
    "silver_train  = spark.table(\"silver_train\")            # date, store_nbr, family, sales, onpromotion, ...\n",
    "silver_stores = spark.table(\"silver_stores\")           # store_nbr, city, state, cluster, type, ...\n",
    "silver_oil    = spark.table(\"silver_oil\")              # date, dcoilwtico\n",
    "silver_hol    = spark.table(\"silver_holidays_events\")  # date, is_holiday, ...\n",
    "silver_tx     = spark.table(\"silver_transactions\")     # date, store_nbr, transactions\n",
    "\n",
    "# =========================================\n",
    "# 3. Build base_fact at date–store–family grain\n",
    "# =========================================\n",
    "\n",
    "# Normalize is_holiday safely to 0/1 int\n",
    "h_str = F.col(\"h.is_holiday\").cast(\"string\")\n",
    "is_holiday_expr = (\n",
    "    F.when(h_str.isin(\"True\", \"true\", \"1\"), F.lit(1))\n",
    "     .when(h_str.isin(\"False\", \"false\", \"0\"), F.lit(0))\n",
    "     .otherwise(F.lit(0))\n",
    "     .cast(\"int\")\n",
    "     .alias(\"is_holiday\")\n",
    ")\n",
    "\n",
    "base_fact = (\n",
    "    silver_train.alias(\"t\")\n",
    "    # Add store attributes (city/state/cluster)\n",
    "    .join(silver_stores.alias(\"s\"), \"store_nbr\", \"left\")\n",
    "    # Daily store-level transactions\n",
    "    .join(silver_tx.alias(\"x\"), [\"date\", \"store_nbr\"], \"left\")\n",
    "    # Oil price by date\n",
    "    .join(silver_oil.alias(\"o\"), \"date\", \"left\")\n",
    "    # Holidays by date\n",
    "    .join(silver_hol.alias(\"h\"), \"date\", \"left\")\n",
    "    .select(\n",
    "        F.col(\"t.id\").alias(\"id\"),\n",
    "        F.col(\"t.date\").alias(\"date\"),\n",
    "        F.col(\"t.store_nbr\").alias(\"store_nbr\"),\n",
    "        F.col(\"t.family\").alias(\"family\"),\n",
    "        F.col(\"t.sales\").cast(\"double\").alias(\"sales\"),\n",
    "        F.col(\"t.onpromotion\").cast(\"int\").alias(\"onpromotion\"),\n",
    "        F.col(\"x.transactions\").cast(\"int\").alias(\"transactions\"),\n",
    "        F.col(\"o.dcoilwtico\").cast(\"double\").alias(\"dcoilwtico\"),\n",
    "        F.col(\"s.city\").alias(\"city\"),\n",
    "        F.col(\"s.state\").alias(\"state\"),\n",
    "        F.col(\"s.type\").alias(\"store_type\"),\n",
    "        F.col(\"s.cluster\").alias(\"cluster\"),\n",
    "        is_holiday_expr\n",
    "    )\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 3b. Add core time features\n",
    "# =========================================\n",
    "base_fact = (\n",
    "    base_fact\n",
    "    .withColumn(\"year\", F.year(\"date\"))\n",
    "    .withColumn(\"month\", F.month(\"date\"))\n",
    "    .withColumn(\"day\", F.dayofmonth(\"date\"))\n",
    "    .withColumn(\"week_of_year\", F.weekofyear(\"date\"))\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"date\"))              # 1=Sun, 7=Sat\n",
    "    .withColumn(\"is_weekend\", F.col(\"day_of_week\").isin(1, 7).cast(\"int\"))\n",
    ")\n",
    "\n",
    "display(base_fact.limit(20))\n",
    "print(\"Rows in base_fact:\", base_fact.count())\n",
    "\n",
    "# =========================================\n",
    "# 4. Save as Gold table: gold_daily_store_family\n",
    "# =========================================\n",
    "\n",
    "# Drop if exists to avoid schema merge issues during development\n",
    "spark.sql(\"DROP TABLE IF EXISTS gold_daily_store_family\")\n",
    "\n",
    "print(\"✅ Created gold_daily_store_family (with time features)\")\n",
    "\n",
    "# Initial write of Gold fact table as managed UC table\n",
    "base_fact.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_daily_store_family\")\n",
    "\n",
    "print(\"✅ Gold table 'gold_daily_store_family' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c80c611-b309-40b0-afaa-b77cf06e5294",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765500049246}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"cscie103_catalog.final_project.gold_daily_store_family\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6843e54-7003-4ba6-9bbc-f2f605dd5b21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM cscie103_catalog.final_project.gold_daily_store_family\n",
    "WHERE sales = 1\n",
    "  AND is_holiday IS NOT NULL LIMIT 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff2423ea-8024-4a23-b85a-5c69703813f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8550468973818895,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04-exploratory-data-analysis-gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
