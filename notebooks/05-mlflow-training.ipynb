{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a622bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mlflow lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3450e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc156b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199af5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = \"store_sales_experiment\"\n",
    "mdl = \"mdl_store_sales\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///kaggle/working/mlruns\")\n",
    "mlflow.set_experiment(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c81cc2",
   "metadata": {},
   "source": [
    "## Load Pre-processed Data\n",
    "\n",
    "Load silver_training and silver_test tables which already contain all necessary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"USE cscie103_catalog.final_project\")\n",
    "\n",
    "tr = spark.table(\"silver_training\").toPandas()\n",
    "ts = spark.table(\"silver_test\").toPandas()\n",
    "\n",
    "# Convert date columns\n",
    "tr[\"date\"] = pd.to_datetime(tr[\"date\"])\n",
    "ts[\"date\"] = pd.to_datetime(ts[\"date\"])\n",
    "\n",
    "print(f\"Training data shape: {tr.shape}\")\n",
    "print(f\"Test data shape: {ts.shape}\")\n",
    "print(f\"\\nTraining columns: {list(tr.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41092f",
   "metadata": {},
   "source": [
    "## Prepare Features\n",
    "\n",
    "Select feature columns (excluding oil since it's not in the pre-processed tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded39125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (no oil)\n",
    "fc = [\"fam\", \"store_nbr\", \"city\", \"state\", \"type\", \"cluster\",\n",
    "      \"hol\", \"sal\", \"eq\", \"transactions\", \"sc\", \"dow\", \"wek\"]\n",
    "\n",
    "# Extract features and target\n",
    "X = tr[fc]\n",
    "y = tr[\"sales\"].astype(float)\n",
    "Xt = ts[fc]\n",
    "\n",
    "print(f\"Feature columns: {fc}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374ec27",
   "metadata": {},
   "source": [
    "## Create Train/Validation Split\n",
    "\n",
    "Split the training data using the last 28 days as validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0332e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = tr[\"date\"].max() - pd.Timedelta(28, \"D\")\n",
    "m1 = tr[\"date\"] <= cut\n",
    "m2 = tr[\"date\"] > cut\n",
    "\n",
    "Xtr = X[m1]\n",
    "ytr = y[m1]\n",
    "Xv = X[m2]\n",
    "yv = y[m2]\n",
    "\n",
    "# Apply log transformation\n",
    "ytrlog = np.log1p(ytr)\n",
    "yvlog = np.log1p(yv)\n",
    "\n",
    "print(f\"Training set: {Xtr.shape[0]} samples\")\n",
    "print(f\"Validation set: {Xv.shape[0]} samples\")\n",
    "print(f\"Validation split date: {cut}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73acf9",
   "metadata": {},
   "source": [
    "## Train Model with MLflow\n",
    "\n",
    "Train LightGBM model with MLflow tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.lightgbm.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"lightgbm_baseline\") as rr:\n",
    "    # Model parameters\n",
    "    p = {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"num_leaves\": 64,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 3,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    mdl1 = lgb.LGBMRegressor(**p)\n",
    "    mdl1.fit(\n",
    "        Xtr, ytrlog,\n",
    "        eval_set=[(Xtr, ytrlog), (Xv, yvlog)],\n",
    "        eval_metric=\"rmse\"\n",
    "    )\n",
    "    \n",
    "    # Validation predictions\n",
    "    vp = mdl1.predict(Xv)\n",
    "    vp = np.expm1(vp).clip(0, None)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    sc = np.sqrt(mean_squared_log_error(yv, vp))\n",
    "    mlflow.log_metric(\"rmsle\", sc)\n",
    "    print(f\"RMSLE: {sc:.6f}\")\n",
    "    \n",
    "    rid = rr.info.run_id\n",
    "    muri = f\"runs:/{rid}/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a92d43",
   "metadata": {},
   "source": [
    "## Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = None\n",
    "try:\n",
    "    x = mlflow.register_model(muri, mdl)\n",
    "    rv = x.version\n",
    "    print(f\"Model registered: version {rv}\")\n",
    "except Exception as e:\n",
    "    print(f\"No registry available: {e}\")\n",
    "\n",
    "if rv:\n",
    "    loadu = f\"models:/{mdl}/{rv}\"\n",
    "else:\n",
    "    loadu = muri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54664610",
   "metadata": {},
   "source": [
    "## Load and Verify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a20ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2load = mlflow.pyfunc.load_model(loadu)\n",
    "vp2 = m2load.predict(Xv)\n",
    "vp2 = np.expm1(vp2).clip(0, None)\n",
    "print(f\"Mean absolute difference: {np.abs(vp - vp2).mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c3417",
   "metadata": {},
   "source": [
    "## Validation Results Visualization\n",
    "\n",
    "### Daily Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = tr[m2].copy()\n",
    "vv[\"p\"] = vp\n",
    "d1 = vv.groupby(\"date\")[[\"sales\", \"p\"]].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(d1[\"date\"], d1[\"sales\"], label=\"Actual\")\n",
    "plt.plot(d1[\"date\"], d1[\"p\"], label=\"Predicted\")\n",
    "plt.title(\"Daily Sales: Actual vs Predicted\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d5630b",
   "metadata": {},
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e59846",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[\"r\"] = d1[\"sales\"] - d1[\"p\"]\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(d1[\"date\"], d1[\"r\"])\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Residuals (Actual - Predicted)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(d1[\"r\"], bins=50, edgecolor=\"black\")\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835c218",
   "metadata": {},
   "source": [
    "### Weekly Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2beead",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv[\"wk\"] = vv[\"date\"].dt.to_period(\"W\").dt.start_time\n",
    "d2 = vv.groupby(\"wk\")[[\"sales\", \"p\"]].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(d2[\"wk\"], d2[\"sales\"], label=\"Actual\")\n",
    "plt.plot(d2[\"wk\"], d2[\"p\"], label=\"Predicted\")\n",
    "plt.title(\"Weekly Sales: Actual vs Predicted\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc7ec1",
   "metadata": {},
   "source": [
    "### Top 6 Product Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518971d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = vv.groupby(\"family\")[\"sales\"].sum().nlargest(6).index\n",
    "\n",
    "for fml in top:\n",
    "    x = vv[vv[\"family\"] == fml].copy()\n",
    "    x = x.groupby(\"date\")[[\"sales\", \"p\"]].sum().reset_index()\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(x[\"date\"], x[\"sales\"], label=\"Actual\")\n",
    "    plt.plot(x[\"date\"], x[\"p\"], label=\"Predicted\")\n",
    "    plt.title(f\"Family: {fml}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Sales\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89787f",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b180de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame({\n",
    "    \"feature\": fc,\n",
    "    \"importance\": mdl1.feature_importances_\n",
    "}).sort_values(\"importance\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(imp[\"feature\"], imp[\"importance\"])\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.grid(axis=\"x\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace404a",
   "metadata": {},
   "source": [
    "## Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = m2load.predict(Xt)\n",
    "tp = np.expm1(tp).clip(0, None)\n",
    "\n",
    "g = ts[[\"date\", \"store_nbr\", \"family\"]].copy()\n",
    "g[\"predicted_sales\"] = tp\n",
    "g.to_csv(\"gold_store_family_day_predictions.csv\", index=False)\n",
    "\n",
    "print(f\"Predictions saved to gold_store_family_day_predictions.csv\")\n",
    "print(f\"Total predictions: {len(g)}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(g.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f83a31",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Model training complete. The trained model has been:\n",
    "- Tracked with MLflow\n",
    "- Evaluated on validation set\n",
    "- Registered in model registry (if available)\n",
    "- Used to generate predictions for test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
