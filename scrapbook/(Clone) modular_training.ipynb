{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffde5687-f133-4907-9e66-b3fdda05d8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['databricks']['catalog'], config['databricks']['schema'], config[\"databricks\"][\"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0aef08a-2d47-46a3-80ea-4adc2d81daf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def running_on_databricks():\n",
    "    \"\"\"Detect if running in Databricks environment\"\"\"\n",
    "    try:\n",
    "        import pyspark.dbutils  # only available in Databricks\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "IS_DATABRICKS = running_on_databricks()\n",
    "print(IS_DATABRICKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "658f5e50-de75-410c-ba09-cfba29862a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# from helper import run_forecast, aggregate_to_granularity, build_features, train_test_split\n",
    "\n",
    "from helper import (\n",
    "    aggregate_to_granularity, assert_unique_series_rows, build_features,\n",
    "    train_test_split, model_factory, assemble_global_pipeline, fit_global_model, predict_global,\n",
    "    compute_metrics, fit_predict_local, rolling_backtest, run_forecast, plot_forecast, plot_train_test_forecast)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Give Spark way more memory since you have 32GB RAM available\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TimeSeriesForecast\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"16\") \\\n",
    "    .config(\"spark.default.parallelism\", \"8\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbbd4ae1-b694-4b28-9257-bdd4a84646bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data (must include columns: date, sales, family, store_nbr)\n",
    "if IS_DATABRICKS:\n",
    "    df_raw = spark.read.format(\"delta\").table('portfolio_catalog.databricks_pipeline.silver_training').withColumn(\"date\", F.to_date(F.col(\"date\")))\n",
    "\n",
    "else:\n",
    "    df_raw = (   \n",
    "        spark.read.parquet('../notebooks/data/train.parquet')\n",
    "\n",
    "        .withColumn(\"date\", F.to_date(F.col(\"date\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36b05eca-a5e4-4166-b4e3-95dfbefd50ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"data\": {\"date_col\": \"date\", \"target_col\": \"sales\", \"group_cols\": [\"family\", \"store_nbr\"],\n",
    "             \"freq\": \"D\", \"min_train_periods\": 56},\n",
    "    \"aggregation\": {\"target_agg\": \"sum\", \"extra_numeric_aggs\": {\"dcoilwtico\": \"mean\", \"onpromotion\": \"sum\"}},\n",
    "    \"features\": {\"lags\": [1,7,14,28], \"mas\": [7,28], \"add_time_signals\": True},\n",
    "    \"split\": {\"mode\": \"horizon\", \"train_end_date\": \"\", \"test_horizon\": 28},\n",
    "    \"model\": {\"type\": \"spark_gbt\", \"params\": {\"maxDepth\": 7, \"maxIter\": 120}},\n",
    "    # \"model\": {\"type\": \"spark_lgbt\", \"params\": {\"maxDepth\": 7, \"maxIter\": 120}},\n",
    "    \"evaluation\": {\"mase_seasonality\": 7, \"backtest\": {\"enabled\": True, \"folds\": 4, \"fold_horizon\": 14, \"step\": 14}}\n",
    "}\n",
    "\n",
    "# --- Step 1: Features ---\n",
    "df_feat = build_features(df_raw, cfg[\"data\"][\"date_col\"], cfg[\"data\"][\"target_col\"],\n",
    "                         cfg[\"data\"][\"group_cols\"], cfg[\"features\"][\"lags\"], cfg[\"features\"][\"mas\"],\n",
    "                         cfg[\"features\"][\"add_time_signals\"], pre_aggregate=True,\n",
    "                         target_agg=cfg[\"aggregation\"][\"target_agg\"],\n",
    "                         extra_numeric_aggs=cfg[\"aggregation\"].get(\"extra_numeric_aggs\"))\n",
    "display(df_feat.limit(5))\n",
    "\n",
    "# --- Step 2: Split ---\n",
    "train, test = train_test_split(df_feat, cfg[\"data\"][\"date_col\"], cfg[\"data\"][\"group_cols\"],\n",
    "                               cfg[\"split\"][\"mode\"], cfg[\"split\"][\"train_end_date\"], cfg[\"split\"][\"test_horizon\"],\n",
    "                               cfg[\"data\"][\"min_train_periods\"])\n",
    "\n",
    "# --- Step 3: Train (global model) ---\n",
    "est = model_factory(cfg[\"model\"][\"type\"], cfg[\"model\"][\"params\"])\n",
    "feature_cols = [c for c in train.columns if c not in cfg[\"data\"][\"group_cols\"] + [cfg[\"data\"][\"date_col\"], cfg[\"data\"][\"target_col\"], \"label\"]]\n",
    "model = fit_global_model(train, cfg[\"data\"][\"target_col\"], cfg[\"data\"][\"group_cols\"], feature_cols, est)\n",
    "\n",
    "# --- Step 4: Predict ---\n",
    "pred = predict_global(model, test, cfg[\"data\"][\"group_cols\"], cfg[\"data\"][\"date_col\"], cfg[\"data\"][\"target_col\"])\n",
    "display(pred.limit(10))\n",
    "\n",
    "# --- Step 5: Metrics ---\n",
    "by_series, portfolio = compute_metrics(pred, cfg[\"data\"][\"date_col\"], \"y\", \"prediction\",\n",
    "                                       cfg[\"data\"][\"group_cols\"], cfg[\"evaluation\"][\"mase_seasonality\"])\n",
    "display(by_series.orderBy(\"wMAPE\")); display(portfolio)\n",
    "\n",
    "# # --- Optional: Backtest ---\n",
    "# from smartforecast.forecasting import aggregate_to_granularity, rolling_backtest\n",
    "# df_agg = aggregate_to_granularity(df_raw, cfg[\"data\"][\"date_col\"], cfg[\"data\"][\"target_col\"],\n",
    "#                                   cfg[\"data\"][\"group_cols\"], cfg[\"aggregation\"][\"target_agg\"],\n",
    "#                                   cfg[\"aggregation\"].get(\"extra_numeric_aggs\"))\n",
    "# bt = rolling_backtest(df_agg, cfg[\"data\"][\"date_col\"], cfg[\"data\"][\"target_col\"], cfg[\"data\"][\"group_cols\"],\n",
    "#                       feature_params={\"lags\": cfg[\"features\"][\"lags\"], \"mas\": cfg[\"features\"][\"mas\"], \"add_time_signals\": cfg[\"features\"][\"add_time_signals\"], \"freq\": cfg[\"data\"][\"freq\"]},\n",
    "#                       model_type=cfg[\"model\"][\"type\"], model_params=cfg[\"model\"][\"params\"],\n",
    "#                       folds=cfg[\"evaluation\"][\"backtest\"][\"folds\"], fold_horizon=cfg[\"evaluation\"][\"backtest\"][\"fold_horizon\"],\n",
    "#                       step=cfg[\"evaluation\"][\"backtest\"][\"step\"], mase_seasonality=cfg[\"evaluation\"][\"mase_seasonality\"])\n",
    "# display(bt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21c8c7d6-046c-440f-816f-ae5df241dd77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "by_series.sort(\"wMAPE\").show(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20fb9939-ea60-4793-a376-34c155c06bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "portfolio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fb565ac-8c69-45c0-a9ae-ed11348a3a2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f633880b-7493-4bbf-b20c-4743a8201557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "family_list = list(pred.toPandas()['family'].unique())\n",
    "i = 0\n",
    "family_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2f420ed-20cf-4707-9801-2b1d9e1c584a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, Window\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "\n",
    "def plot_forecast(\n",
    "    pred_df: DataFrame,\n",
    "    date_col: str,\n",
    "    actual_col: str,\n",
    "    pred_col: str,\n",
    "    group_cols: List[str],\n",
    "    series_id: Dict[str, str] = None,\n",
    "    title: str = \"Forecast vs Actual\",\n",
    "    figsize: Tuple[int, int] = (10, 5),\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot actual vs predicted for a single series.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred_df : DataFrame\n",
    "        Must include date_col, actual_col, pred_col, and group_cols.\n",
    "    series_id : dict\n",
    "        Filter for one series, e.g., {\"family\": \"BEVERAGES\"} or {\"family\": \"BEVERAGES\", \"store_nbr\": \"1\"}.\n",
    "    \"\"\"\n",
    "    # Filter for one series\n",
    "    # After filtering and sorting\n",
    "    \n",
    "    pdf = pred_df.sort_values(date_col)\n",
    "    print(pdf.head(5))\n",
    "\n",
    "    # Aggregate only if needed\n",
    "    if pdf.duplicated(subset=[date_col]).any():\n",
    "        pdf = (\n",
    "            pdf.groupby([date_col] + group_cols, as_index=False)\n",
    "            .agg({actual_col: \"sum\", pred_col: \"sum\"})\n",
    "            .sort_values(date_col)\n",
    "        )\n",
    "\n",
    "    if series_id:\n",
    "        for k, v in series_id.items():\n",
    "            pdf = pdf[pdf[k] == v]\n",
    "\n",
    "    pdf = pdf.sort_values(date_col)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(pdf[date_col], pdf[actual_col], label=\"Actual\", color=\"blue\")\n",
    "    plt.plot(\n",
    "        pdf[date_col], pdf[pred_col], label=\"Prediction\", color=\"orange\", linestyle=\"--\"\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(actual_col)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c101739e-d92a-4c42-959b-ac443f3fb886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_df = pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45b82857-a430-4515-b38d-7fb73555c997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: plot for one family\n",
    "selected_family = family_list[i]\n",
    "plot_forecast(\n",
    "    pred_df=pred_df,\n",
    "    date_col=cfg[\"data\"][\"date_col\"],\n",
    "    actual_col=\"y\",\n",
    "    pred_col=\"prediction\",\n",
    "    group_cols=['family'], #cfg[\"data\"][\"group_cols\"],\n",
    "    series_id={\"family\": selected_family},\n",
    "    title=f\"Family {selected_family} Forecast\"\n",
    ")\n",
    "i +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2900e027-c378-444a-b3aa-0425ef70a833",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_train_test_forecast(train, test, pred,\n",
    "                         date_col=cfg[\"data\"][\"date_col\"],\n",
    "                         target_col=\"sales\",\n",
    "                         pred_col=\"prediction\",\n",
    "                         group_cols=cfg[\"data\"][\"group_cols\"],\n",
    "                         series_id={\"family\": selected_family}, last_n_train=120)\n",
    "\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e629c6d-ad13-481a-93fe-0f88e53e6718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_forecast(df, cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efd96a8f-3d02-4e59-8036-8fbcfac29008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agg_cols = ['family', 'store_nbr', 'state', 'city', 'type', 'cluster'] # there is one store per city and type and cluster so adding those feature is redundant\n",
    "agg_cols = ['family', 'store_nbr'] # there is one store per city and type and cluster so adding those feature is redundant\n",
    "\n",
    "# agg_cols = ['family']\n",
    "\n",
    "df_agg = aggregate_to_granularity(\n",
    "    df=df,\n",
    "    date_col='date',\n",
    "    target_col='sales',\n",
    "    group_cols=agg_cols,\n",
    "    agg=\"sum\",  # sales are additive\n",
    "    # extra_numeric_aggs={\"dcoilwtico\": \"mean\"}  # optional\n",
    ")\n",
    "print(df_agg.count())\n",
    "df_agg.show(2)\n",
    "\n",
    "df_feat = build_features(\n",
    "    df=df_agg,\n",
    "    date_col='date',\n",
    "    target_col='sales',\n",
    "    group_cols=agg_cols,\n",
    "    lags=[1, 7, 14, 28],\n",
    "    mas=[7, 28],\n",
    "    # add_time_signals=cfg[\"features\"][\"add_time_signals\"]\n",
    ")\n",
    "df_feat.show(10)\n",
    "print(df_feat.count())\n",
    "# df_feat.sort(agg_cols + [\"date\"]).select(agg_cols + ['date', 'sales', 'dcoilwtico', 'lag_1', 'lag_2']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7293a416-bdc3-47d3-8574-d66f3089f0e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "\n",
    "d, a, f, s, m, e = (\n",
    "    cfg[\"data\"],\n",
    "    cfg.get(\"aggregation\", {}),\n",
    "    cfg[\"features\"],\n",
    "    cfg[\"split\"],\n",
    "    cfg[\"model\"],\n",
    "    cfg[\"evaluation\"],\n",
    ")\n",
    "\n",
    "df_agg = aggregate_to_granularity(\n",
    "    df_raw,\n",
    "    d[\"date_col\"],\n",
    "    d[\"target_col\"],\n",
    "    d[\"group_cols\"],\n",
    "    agg=a.get(\"target_agg\", \"sum\"),\n",
    "    extra_numeric_aggs=a.get(\"extra_numeric_aggs\"),\n",
    ")\n",
    "ic()\n",
    "\n",
    "bt = rolling_backtest(\n",
    "    df_agg,\n",
    "    d[\"date_col\"],\n",
    "    d[\"target_col\"],\n",
    "    d[\"group_cols\"],\n",
    "    feature_params={\n",
    "        \"lags\": f[\"lags\"],\n",
    "        \"mas\": f[\"mas\"],\n",
    "        \"add_time_signals\": f[\"add_time_signals\"],\n",
    "        \"freq\": d.get(\"freq\", \"D\"),\n",
    "    },\n",
    "    model_type=m[\"type\"],\n",
    "    model_params=m[\"params\"],\n",
    "    folds=e[\"backtest\"][\"folds\"],\n",
    "    fold_horizon=e[\"backtest\"][\"fold_horizon\"],\n",
    "    step=e[\"backtest\"][\"step\"],\n",
    "    mase_seasonality=e[\"mase_seasonality\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a87ccd53-fbde-4c99-8736-ebea1b683fa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40006404-00c5-4ccc-83e0-7aa171da6e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# agg_cols = ['family', 'store_nbr']\n",
    "agg_cols = ['family']\n",
    "\n",
    "df_agg = aggregate_to_granularity(\n",
    "    df=df,\n",
    "    date_col='date',\n",
    "    target_col='sales',\n",
    "    group_cols=agg_cols,\n",
    "    agg=\"sum\",  # sales are additive\n",
    "    # extra_numeric_aggs={\"price\": \"mean\", \"promo_spend\": \"sum\"}  # optional\n",
    ")\n",
    "\n",
    "df_feat = build_features(\n",
    "    df=df_agg,\n",
    "    date_col='date',\n",
    "    target_col='sales',\n",
    "    group_cols=agg_cols,\n",
    "    lags=[1,2],\n",
    "    mas=[1,2],\n",
    "    # add_time_signals=cfg[\"features\"][\"add_time_signals\"]\n",
    ")\n",
    "print(df_feat.count())\n",
    "df_feat.sort(agg_cols + [\"date\"]).select(agg_cols + ['date', 'sales', 'lag_1', 'lag_2']).show(10)\n",
    "df_feat.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bd3b80f-f504-4891-8b29-7291a38e4aed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df=df_feat, date_col='date', group_cols=agg_cols, mode='horizon', test_horizon=28)\n",
    "train.show(2)\n",
    "test.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1623662f-9888-4636-87a2-5a6cbcf5c721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agg_cols = ['family', 'family']\n",
    "# agg_cols = ['family']\n",
    "\n",
    "df_agg = aggregate_to_granularity(\n",
    "    df=df,\n",
    "    date_col='date',\n",
    "    target_col='sales',\n",
    "    group_cols=agg_cols,\n",
    "    agg=\"sum\",  # sales are additive\n",
    "    # extra_numeric_aggs={\"price\": \"mean\", \"promo_spend\": \"sum\"}  # optional\n",
    ")\n",
    "\n",
    "df_feat = build_features(\n",
    "    df=df_agg,\n",
    "    date_col='date',\n",
    "    target_col='sales',\n",
    "    group_cols=agg_cols,\n",
    "    lags=[1,2],\n",
    "    mas=[1,2],\n",
    "    # add_time_signals=cfg[\"features\"][\"add_time_signals\"]\n",
    ")\n",
    "print(df_feat.count())\n",
    "df_feat.sort(agg_cols + [\"date\"]).select(agg_cols + ['date', 'sales', 'lag_1', 'lag_2']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "710711de-6b5a-403c-a614-0ab11d24c1cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1131192c-0fb0-4b9a-adf4-6dfcb3d7c077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfx = build_features(df, \"date\", \"sales\", [\"family\", \"store_nbr\"], lags=[1, 2], mas=[1])\n",
    "print(dfx.count())\n",
    "dfx.sort([\"family\", \"store_nbr\", \"date\"]).select(['family', 'store_nbr', 'date', 'sales', 'lag_1', 'lag_2']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6bc9ead-2047-4f14-a413-337c01894f4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfx = build_features(df, \"date\", \"sales\", [\"family\"], lags=[1, 2], mas=[1])\n",
    "print(dfx.count())\n",
    "dfx.sort([\"family\", \"store_nbr\", \"date\"]).select(['family', 'store_nbr', 'date', 'sales', 'lag_1', 'lag_2']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d294cac-705d-442f-b42d-43c04918821a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load config from YAML or dict\n",
    "import yaml, json\n",
    "cfg = yaml.safe_load(open(\"forecast_config.yaml\"))\n",
    "\n",
    "out = run_forecast(df_feat, cfg)\n",
    "\n",
    "display(out[\"predictions\"])         # per-group predictions on test window\n",
    "# display(out[\"metrics_portfolio\"])   # wMAPE, sMAPE, MASE overall\n",
    "# display(out[\"metrics_by_series\"])   # same metrics by series\n",
    "# display(out[\"backtest\"])            # rolling-origin backtest summary (if enabled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fb7d137-2755-4482-bdc5-60f77fb6718d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) modular_training",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "databricks_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
